# -*- coding: utf-8 -*-
"""CV CW 2024.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J3Pk4RCPrZIP-z4ymLvTj99ib2pDojZp
"""

#LOADING DATA
#from google.colab import drive
#drive.mount('/content/drive')

import numpy as np
import tensorflow as tf
from tensorflow.python import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
#import tensorflow as tf
from keras.optimizers import Adam

from sklearn.model_selection import train_test_split

# Load the data using np.load
data = np.load('path/to/local/training_images.npz', allow_pickle=True)
# Extract the images
images = data['images']
# and the data points
pts = data['points']

print(images.shape, pts.shape)



test_data = np.load('path/to/local/test_images.npz', allow_pickle=True)
test_images = test_data['images']
print(test_images.shape)

example_data = np.load('path/to/local/examples.npz', allow_pickle=True)
example_images = example_data['images']
print(example_images.shape)

def visualise_pts(img, pts):
  import matplotlib.pyplot as plt
  plt.imshow(img)
  plt.plot(pts[:, 0], pts[:, 1], '+r')
  plt.show()

for i in range(3):
  idx = np.random.randint(0, images.shape[0])
  visualise_pts(images[idx, ...], pts[idx, ...])

# Normalize the images
images = images.astype('float32') / 255.0
test_images = test_images.astype('float32') / 255.0
example_images = example_images.astype('float32') / 255.0

# Flatten the points
pts = pts.reshape(pts.shape[0], -1)

# Split the data into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(images, pts, test_size=0.2, random_state=42)

# Define/Create CNN MODEL
def create_cnn_model(input_shape, num_landmarks):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),
        MaxPooling2D((2, 2)),
        Dropout(0.2),
        Conv2D(64, (3, 3), activation='relu', padding='same'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu', padding='same'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.4),
        Dense(num_landmarks)  # Adjust the output size based on the number of landmarks
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])
    return model

# Assuming y_train.shape[1] contains the number of landmarks
num_landmarks = y_train.shape[1]
model = create_cnn_model((252, 252, 3), num_landmarks)
model.summary()

# Training the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))

#testing on example dataset
example_pts = model.predict(example_images)
example_pts = example_pts.reshape(example_pts.shape[0], -1, 2)

# Visualize the results
for i in range(3):
    idx = np.random.randint(0,6)
    visualise_pts(example_images[idx, ...], example_pts[idx, ...])

from sklearn.metrics import mean_squared_error

test_pts = model.predict(X_val)
mse = mean_squared_error(y_val, test_pts)
print("Mean squared error:", mse)

test_pts = model.predict(test_images)
test_pts = test_pts.reshape(test_pts.shape[0], -1, 2)

# Visualize the results
for i in range(3):
    idx = np.random.randint(0, test_images.shape[0])
    visualise_pts(test_images[idx, ...], test_pts[idx, ...])

import cv2
import numpy as np
import matplotlib.pyplot as plt

def create_mask_for_color_transformation(image, pts, region_indices):
    mask = np.zeros(image.shape[:2], dtype=np.uint8)
    # Assuming these landmark points correspond to the region (lips or eyes)
    region = pts[region_indices].reshape((-1, 1, 2)).astype(np.int32)
    cv2.fillPoly(mask, [region], (255, 255, 255))
    return mask

def change_color(image, pts, region_indices, color):
    mask = create_mask_for_color_transformation(image, pts, region_indices)
    colored_image = np.zeros_like(image)
    colored_image[:] = color
    colored_region = cv2.bitwise_and(colored_image, colored_image, mask=mask)
    final_image = cv2.bitwise_and(image, image, mask=cv2.bitwise_not(mask))
    final_image = cv2.add(final_image, colored_region)
    return final_image

def visualise_pts(img, pts):
    plt.imshow(img)
    plt.scatter(pts[:, 0], pts[:, 1], c='r', s=10)
    plt.show()

import numpy as np
for i in range(3):
    idx = np.random.randint(0, example_images.shape[0])
    image = example_images[idx] * 255  # Convert back to original range
    image = image.astype(np.uint8)
    pts = example_pts[idx].astype(np.int32)

    # Indices of landmarks for lips and eyes
    lips_indices = np.concatenate((np.arange(30, 49), np.arange(41, 37)))  # Adjust these indices to your landmarks
    eyes_indices = np.concatenate((np.arange(18, 23), np.arange(24, 29)))  # Adjust these indices to your landmarks

    # Change lip color
    modified_image = change_color(image, pts, lips_indices, [255, 0, 0])  # Change lips to red (BGR format)

    # Change eye color
    modified_image = change_color(modified_image, pts, eyes_indices, [0, 255, 0])  # Change eyes to green (BGR format)

    # Visualize the result
    visualise_pts(modified_image, pts)

"""CASCADE CLASSIFICATION"""


import numpy as np
import tensorflow as tf
#from tensorflow.keras.models import Sequential
#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
#from tensorflow.keras.optimizers import Adam
#from sklearn.model_selection import train_test_split



# Load the data using np.load
data= np.load('C:\Users\Admin\Desktop\CV2024CW/training_images.npz', allow_pickle=True)

# Extract the images and data points
images = data['images']
pts = data['points']

# Load test images
test_data = np.load('C:\Users\Admin\Desktop\CV2024CW/test_images.npz', allow_pickle=True)
test_images = test_data['images']

# Load example images
example_data = np.load('C:\Users\Admin\Desktop\CV2024CW/examples.npz', allow_pickle=True)
example_images = example_data['images']

# Normalize the images
images = images.astype('float32') / 255.0
test_images = test_images.astype('float32') / 255.0
example_images = example_images.astype('float32') / 255.0

# Flatten the points
pts = pts.reshape(pts.shape[0], -1)

# Split the data into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(images, pts, test_size=0.1, random_state=42)

import tensorflow as tf
from tensorflow.python import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout

def create_model():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(252, 252, 3)),
        MaxPooling2D(2, 2),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Flatten(),
        Dense(500, activation='relu'),
        Dropout(0.3),
        Dense(500, activation='relu'),
        Dropout(0.3),
        Dense(96)  # Adjust this number based on your landmarks (2 * number of landmarks)
    ])

    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])
    return model

model = create_model()
model.summary()

# This is a placeholder for your data loading and preprocessing code



# Train the model

history = model.fit(images, pts, epochs=50, validation_split=0.2)
#history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))



import cv2
def preprocess_image(image):
    # Resize, normalize, and expand dimensions as required for the model
#    image = cv2.resize(image, (96, 96)) # Resize to model input size
    image = image / 255.0 # Normalize pixel values
    image = np.expand_dims(image, axis=-1) # Add channel dimension if grayscale
    return image

def predict_landmarks(image):
    processed_image = preprocess_image(image)
    landmarks = model.predict(np.expand_dims(processed_image, axis=0))
    return landmarks

# Example usage
#images = # Load an image here
predicted_landmarks = predict_landmarks(images)

def visualise_pts(img, pts):
  import matplotlib.pyplot as plt
  plt.imshow(img)
  plt.plot(pts[:, 0], pts[:, 1], '+r', ms=7)
  plt.show()

example_pts = model.predict(example_images)
example_pts = example_pts.reshape(example_pts.shape[0], -1, 2)

# Visualize the results
for i in range(3):
    idx = np.random.randint(0, example_images.shape[0])
    visualise_pts(example_images[idx, ...], example_pts[idx, ...])

import cv2
import numpy as np
import random


# Load the face cascade classifier
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Load test images
test_data = np.load('C:\Users\Admin\Desktop\CV2024CW/test_images.npz', allow_pickle=True)
test_images = test_data['images']
test_images = test_images.astype('float32') / 255.0
input_size = (252, 252)

def detect_faces(image, face_cascade):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    return faces

def preprocess_faces(image, faces, target_size=(252, 252)):
    cropped_faces = []
    for (x, y, w, h) in faces:
        face = image[y:y+h, x:x+w]
        resized_face = cv2.resize(face, target_size)
        cropped_faces.append(resized_face)
    return cropped_faces

def visualize_landmarks(image, landmarks, x_offset, y_offset):
    for point in landmarks:
        x, y = int(point[0] + x_offset), int(point[1] + y_offset)
        cv2.circle(image, (x, y), 2, (0, 255, 0), -1)
    return image


# Detect faces and plot points on 3 random test images

random_indices = random.sample(range(len(test_images)), 3)
for i in random_indices:
    image = (test_images[i] * 255).astype(np.uint8)
    faces = detect_faces(image, face_cascade)

    for (x, y, w, h) in faces:
        face = image[y:y+h, x:x+w]
        resized_face = cv2.resize(face, input_size)
        resized_face_normalized = resized_face.astype('float32') / 255.0
        resized_face_normalized = np.expand_dims(resized_face_normalized, axis=0)

        # Predict landmarks
        predicted_points = model.predict(resized_face_normalized)
        predicted_points = predicted_points.reshape(-1, 2)

        # Scale the points back to the cropped face size
        predicted_points[:, 0] *= w / input_size[0]
        predicted_points[:, 1] *= h / input_size[1]

        visualize_landmarks(image, predicted_points, x, y)

    # Display the image with landmarks
    cv2.imshow(image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

def visualise_pts(image, pts):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert the image to BGR format
    for point in pts:
        x, y = int(point[0]), int(point[1])
        cv2.circle(image, (x, y), 5, (0, 0, 255), -1)  # Draw a red circle at each point with a larger radius

    cv2.imshow(image)

"""MEAN SQUARE ERROR FOR THE METHOD"""

array = []

from sklearn.metrics import mean_squared_error

test_pts = model.predict(X_val)
mse = mean_squared_error(y_val, test_pts)
print("Mean squared error:", mse)
array.append(mse)

